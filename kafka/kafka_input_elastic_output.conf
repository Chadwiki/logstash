# Tested on LS 5.4.0
# Author Chad Pryor
# Version 1.0
# Modified 2017.05.25
# https://github.com/logstash-plugins/logstash-input-kafka
# FIX ADD Plugin IDs, add template

input {  
    kafka {  
            #bootstrap_servers => "localhost:9092"
            bootstrap_servers => "192.168.0.191:9092"
            topics=> ["beats" ,"beats_in"]
            client_id => "logstash_kafka_input"
            #group_id => "logstash"
            consumer_threads => 2
            type => "beat"
            #auto_offset_reset => none
            #auto_offset_reset => earliest
            #value_deserializer_class => "org.apache.kafka.common.serialization.ByteArrayDeserializer"
            add_field => {"kafka_topic_id" => "kafka_test_id" }
            #tags => [ "%{[@metadata][beat]}" ]
            #codec => json
        }
    }

    filter{
        json{ source => "message" }
        mutate {
            add_field => { "pipeline_stage" => 2 }
        }
    }
    #filter { drop { remove_field => [ "message" ] } }

    output { 
       stdout { codec => rubydebug }
       elasticsearch {
        # hosts => [ "one:9200", "two:9200", "three:9200" ]
        hosts => "localhost"
        index => "metricbeat-k-%{+yyyy-MM-dd}"
        user => "elastic"
        password => "changeme"
        document_type => "%{type}"
        #user => "logstash_internal"
        #password => "${LS_WRITE_PASSWORD}"
    }  
}

